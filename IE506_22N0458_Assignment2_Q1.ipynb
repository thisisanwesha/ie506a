{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOgwm-M1eYWx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eF_iHgvR54KL"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier1\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_validate\n",
        "import multiprocessing\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import LinearSVC\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5lt45nS-y4S"
      },
      "source": [
        "### Answer a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxisWVSFZjs7",
        "outputId": "2095f5a1-d9c9-4387-fc0d-6ff542d120c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[ 1. -1. -1. ...  1. -1.  1.]\n"
          ]
        }
      ],
      "source": [
        "with open('Data_Q1.txt','r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "no_of_samples=len(lines)\n",
        "\n",
        "y=np.zeros(no_of_samples)\n",
        "\n",
        "d={}\n",
        "m=[]\n",
        "\n",
        "for i in range(no_of_samples):\n",
        "  l=lines[i].split()\n",
        "  y[i]=l[0]\n",
        "  X_dict={}\n",
        "  for j in l[1:]:\n",
        "    k=j.split(':')\n",
        "    X_dict[int(k[0])]=int(k[1])\n",
        "  m.append(max(X_dict.keys()))\n",
        "  d[i+1]=X_dict\n",
        "\n",
        "no_of_features=max(m)\n",
        "\n",
        "X=np.zeros((no_of_samples, no_of_features))\n",
        "\n",
        "for k2,v in d.items():\n",
        "  for k1,v1 in v.items():\n",
        "    X[k2-1][k1-1]=v1\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((no_of_samples, no_of_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zHBMxCLEQHo",
        "outputId": "678f49dc-03e4-4530-a311-79ed560917fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4143, 54877)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHf3afO0ELDb",
        "outputId": "4c77c08a-e548-45fa-c662-6a360608e717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4143, 54877)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxHH4TRNVSr3"
      },
      "outputs": [],
      "source": [
        "my_matrix=X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IVvxfXjVKTI",
        "outputId": "967c75de-119c-4fab-994a-e0707602f4cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06151249 0.10554605 0.1291997  0.14915661 0.16583007 0.17891754\n",
            " 0.19130718 0.20264855 0.2128589  0.22274433 0.23229439 0.24062825\n",
            " 0.2482886  0.25581608 0.26315092 0.26967828 0.27586312 0.28186658\n",
            " 0.2876791  0.29331067 0.29892204 0.30427433 0.30956145 0.31472194\n",
            " 0.31966877 0.32443239 0.3289975  0.33352215 0.33797888 0.34224001\n",
            " 0.34643139 0.35059192 0.3546258  0.35854086 0.36240983 0.36623747\n",
            " 0.3699218  0.37357193 0.37711375 0.38056736 0.38399015 0.38733268\n",
            " 0.39064541 0.39388086 0.39708878 0.40021163 0.40328667 0.40633915\n",
            " 0.40936083 0.41232849 0.41528644 0.41815654 0.42097173 0.42375116\n",
            " 0.42643715 0.42908486 0.43169565 0.43423838 0.43675617 0.43927008\n",
            " 0.44175135 0.44418376 0.44661012 0.44897991 0.45132254 0.45365853\n",
            " 0.45598168 0.45822013 0.46044395 0.46263343 0.46480956 0.46695911\n",
            " 0.46907389 0.47116247 0.47323623 0.47526996 0.47728671 0.4792883\n",
            " 0.48127499 0.48324654 0.48520248 0.48714164 0.4890487  0.49094193\n",
            " 0.49282388 0.49465412 0.49646814 0.4982701  0.50006522 0.50184974\n",
            " 0.50362337 0.50537253 0.50711074 0.5088269  0.51052907 0.51222056\n",
            " 0.51390104 0.51556395 0.51722366 0.51886225 0.52048065 0.52208004\n",
            " 0.52367508 0.52525244 0.52681251 0.52836855 0.52990916 0.53142309\n",
            " 0.53293196 0.53443854 0.5359154  0.53738142 0.53884134 0.54028503\n",
            " 0.54172349 0.54315617 0.54457134 0.54598043 0.54737141 0.54875825\n",
            " 0.5501396  0.55149948 0.55285269 0.55420127 0.55554597 0.5568824\n",
            " 0.55821149 0.55952826 0.56084001 0.56212307 0.56339757 0.56466682\n",
            " 0.56592245 0.56717648 0.56842244 0.56965912 0.57089018 0.57211386\n",
            " 0.57332337 0.574531   0.57572556 0.57691779 0.57810422 0.57927575\n",
            " 0.58043899 0.5815984  0.58274986 0.58388478 0.58501276 0.58613422\n",
            " 0.58725169 0.58836257 0.58947021 0.5905654  0.59165441 0.5927384\n",
            " 0.59381716 0.59488865 0.59594348 0.59699358 0.59804068 0.59908584\n",
            " 0.60011813 0.60114498 0.60216784 0.60318246 0.6041949  0.60520111\n",
            " 0.6062027  0.60719667 0.60818634 0.60917248 0.61015054 0.61112143\n",
            " 0.61209063 0.6130528  0.61400959 0.6149639  0.61591393 0.61685942\n",
            " 0.61780288 0.61874022 0.61967668 0.62060468 0.6215323  0.62244934\n",
            " 0.62336307 0.62427374 0.62517894 0.62608284 0.62697999 0.62787538\n",
            " 0.62875862 0.62964031 0.63052079 0.63139959 0.63227539 0.63314249\n",
            " 0.63400756 0.63486712 0.63572651 0.63658008 0.63743113 0.63828055\n",
            " 0.63912263 0.63995986 0.64079551 0.64162385 0.64244954 0.64327505\n",
            " 0.64409595 0.64491213 0.64572586 0.64653165 0.64733614 0.6481374\n",
            " 0.64893533 0.64973092 0.65052496 0.65131562 0.65210419 0.65288841\n",
            " 0.65366853 0.65444568 0.65521912 0.65599099 0.6567604  0.65752618\n",
            " 0.65828994 0.65904734 0.65980097 0.66055109 0.66129847 0.66204064\n",
            " 0.66278217 0.66352011 0.6642542  0.66498717 0.66571774 0.66644803\n",
            " 0.66717548 0.66789837 0.66861942 0.66933749 0.67005483 0.6707643\n",
            " 0.6714733  0.67217821 0.672882   0.67358138 0.6742794  0.67497445\n",
            " 0.67566611 0.67635539 0.67704291 0.67772922 0.67841466 0.67909727\n",
            " 0.67977886 0.68045558 0.68112785 0.6817996  0.68246643 0.68313206\n",
            " 0.6837961  0.6844585  0.68511877 0.68577885 0.6864345  0.68708873\n",
            " 0.68774165 0.6883921  0.68904102 0.68968595 0.69032784 0.69096877\n",
            " 0.69160815 0.69224571 0.69288018 0.69351226 0.69414129 0.6947696\n",
            " 0.69539395 0.69601583 0.69663704 0.69725715 0.69787289 0.69848829\n",
            " 0.69910037 0.69970941 0.70031815 0.70092562 0.70153045 0.70213412\n",
            " 0.70273546 0.70333609 0.70393513 0.70452978 0.70512252 0.70571304\n",
            " 0.70630262 0.70689034 0.70747542 0.70805927 0.70863986 0.70921924\n",
            " 0.70979752 0.71037332 0.71094727 0.71151996 0.71209044 0.71265972\n",
            " 0.7132255  0.71379062 0.71435354 0.71491531 0.7154757  0.71603283\n",
            " 0.71658725 0.71714085 0.71769299 0.7182446  0.7187939  0.71934149\n",
            " 0.71988798 0.72043312 0.72097704 0.72151994 0.72205997 0.72259828\n",
            " 0.72313392 0.7236693  0.72420283 0.72473361 0.7252632  0.7257909\n",
            " 0.72631826 0.72684413 0.72736882 0.72789174 0.72841367 0.72893226\n",
            " 0.72944925 0.72996522 0.73048004 0.73099217 0.731503   0.73201282\n",
            " 0.73252181 0.73302921 0.73353575 0.73404048 0.7345442  0.73504669\n",
            " 0.73554803 0.73604793 0.73654648 0.7370431  0.73753722 0.73803007\n",
            " 0.73852189 0.73901279 0.73950302 0.73999174 0.74047835 0.74096417\n",
            " 0.7414476  0.74192955 0.74241108 0.74289103 0.74337006 0.74384715\n",
            " 0.74432201 0.74479652 0.74527076 0.74574275 0.74621309 0.74668281\n",
            " 0.74715016 0.74761543 0.74807987 0.74854316 0.74900474 0.74946544\n",
            " 0.74992513 0.75038374 0.75084088 0.75129664 0.75174955 0.75220178\n",
            " 0.75265305 0.75310327 0.75355231 0.75399989 0.75444598 0.75489046\n",
            " 0.75533338 0.75577483 0.75621549 0.75665494 0.75709373 0.75753113\n",
            " 0.75796785 0.7584031  0.75883688 0.75926965 0.75970147 0.76013275\n",
            " 0.76056269 0.76099161 0.76141989 0.76184511 0.76227019 0.76269382\n",
            " 0.76311565 0.76353734 0.76395803 0.76437802 0.76479596 0.76521353\n",
            " 0.765629   0.76604283 0.76645616 0.76686773 0.76727819 0.76768757\n",
            " 0.7680964  0.76850314 0.76890938 0.76931459 0.76971736 0.77011925\n",
            " 0.77052069 0.77092117 0.77132154 0.77172018 0.7721175  0.77251412\n",
            " 0.77291051 0.77330464 0.7736986  0.77409153 0.77448272 0.77487254\n",
            " 0.77525995 0.7756466  0.77603281 0.77641739 0.77680117 0.77718449\n",
            " 0.77756613 0.77794675 0.77832723 0.77870657 0.77908404 0.77946112\n",
            " 0.7798371  0.78021156 0.78058565 0.78095777 0.78132794 0.78169716\n",
            " 0.78206523 0.78243235 0.78279817 0.78316237 0.78352532 0.78388743\n",
            " 0.78424864 0.7846092  0.7849695  0.78532774 0.78568476 0.78604095\n",
            " 0.78639581 0.78675058 0.78710362 0.78745493 0.78780618 0.78815576\n",
            " 0.78850445 0.78885204 0.78919856 0.78954398 0.78988852 0.79023169\n",
            " 0.79057352 0.79091419 0.7912528  0.79159133 0.79192894 0.7922661\n",
            " 0.79260198 0.79293656 0.7932698  0.79360259 0.79393499 0.79426599\n",
            " 0.79459617 0.7949254  0.79525209 0.79557814 0.79590266 0.79622588\n",
            " 0.79654765 0.79686932 0.79718994 0.79750906 0.79782741 0.79814468\n",
            " 0.79846003 0.79877418 0.79908732 0.79939938 0.79970989 0.80001932\n",
            " 0.80032708 0.80063211 0.80093698 0.80123949]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "my_model = PCA(n_components=520)\n",
        "X_new=my_model.fit_transform(my_matrix)\n",
        "\n",
        "print (my_model.explained_variance_ratio_.cumsum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZeMPaxLZjBe",
        "outputId": "1e117be7-7cc8-49e1-e238-7ab52e09a592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-3.16355559e+00  1.35449233e+00  1.22609270e-01 ...  1.73978686e-02\n",
            "   2.22212971e-02 -6.84901145e-03]\n",
            " [ 2.94461102e+00 -1.85303372e+00 -3.42356930e+00 ...  1.73635200e-01\n",
            "   7.04242106e-02  2.76140411e-02]\n",
            " [-2.42472556e+00  1.07460981e+00 -9.15473283e-02 ... -5.85720272e-02\n",
            "   6.17565303e-02  2.56509028e-01]\n",
            " ...\n",
            " [ 8.89478955e-01 -9.01727203e-01  2.04859233e+00 ...  3.24235490e-01\n",
            "  -2.87580279e-01 -3.15313683e-01]\n",
            " [-1.75517906e+00  5.72070548e-01  1.17252505e-01 ...  1.67895041e-01\n",
            "   5.39460948e-02 -1.55764081e-01]\n",
            " [ 1.22167361e+01  1.40410531e+01 -6.38559837e-01 ... -1.06704488e-01\n",
            "  -1.66070607e-01 -2.07106818e-01]]\n"
          ]
        }
      ],
      "source": [
        "print(X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfSZscSyDN44"
      },
      "outputs": [],
      "source": [
        "X=X_new"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyzyCVKPEGPT",
        "outputId": "853d1370-22f0-4d54-c008-f47cb9d40c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4143, 520)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(no_of_samples, no_of_features)=X.shape"
      ],
      "metadata": {
        "id": "TNvdKok9EVjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comments: The original matrix X had 54877 features and ram kept crashing. So, I did data preprocessing to reduce the number of features. As sir suggested, I used PCA with the threshold that 80% of the variance of the original dataset was captured in the processed dataset. The number of features actually comes out to be 514 but still I have taken 520 features."
      ],
      "metadata": {
        "id": "vCyaifTNVa6T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBqR8ntF-33D"
      },
      "source": [
        "### Answer b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZwwJAXwxxy5"
      },
      "outputs": [],
      "source": [
        "classes, freq = np.unique(y, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH8GKvLOyCPS",
        "outputId": "ca7f42b2-e4bf-431e-eccb-a4cc475aea7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of classes: 2\n"
          ]
        }
      ],
      "source": [
        "print(\"No of classes:\", len(classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5xf47ZIx2Dk",
        "outputId": "b0edafc7-8ba6-402d-d8f0-0a3dc232dbdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of samples belonging to class -1.0 is 1933\n",
            "No of samples belonging to class 1.0 is 2210\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(classes)):\n",
        "  print(\"No of samples belonging to class\", classes[i], \"is\", freq[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UroB-nqGw7D0"
      },
      "source": [
        "There is no class imbalance issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qtjFWav-uA6"
      },
      "source": [
        "### Answer c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpo-FiDwvwlx"
      },
      "outputs": [],
      "source": [
        "df=pd.DataFrame(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "-V_gGkbbv06m",
        "outputId": "6604fffd-0a37-4cd6-f92c-bc96ab30c0bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0          1         2         3         4         5         6    \\\n",
              "0     -3.163556   1.354492  0.122609  0.614129 -0.325644 -0.765679 -0.197722   \n",
              "1      2.944611  -1.853034 -3.423569 -3.943277 -3.041524  3.619496 -3.783854   \n",
              "2     -2.424726   1.074610 -0.091547  0.004458 -0.401874 -0.567940 -0.354899   \n",
              "3     -1.785259   0.864062  0.235106  0.025431  0.331659  0.115276 -0.176223   \n",
              "4     -3.167082   1.337177  0.047686  0.561414 -0.369034 -0.765479 -0.196355   \n",
              "...         ...        ...       ...       ...       ...       ...       ...   \n",
              "4138  -1.446324   0.642952 -0.330377 -0.011503 -0.000712 -0.501163  0.366723   \n",
              "4139  -0.368333   0.016102  0.309881  0.342469 -0.103763 -0.023977  0.059648   \n",
              "4140   0.889479  -0.901727  2.048592  0.134772 -0.032090  0.193295  0.155847   \n",
              "4141  -1.755179   0.572071  0.117253  0.273678 -0.116884 -0.404077 -0.023015   \n",
              "4142  12.216736  14.041053 -0.638560  0.219674  0.336044 -0.271704 -0.013033   \n",
              "\n",
              "           7         8         9    ...       510       511       512  \\\n",
              "0     0.345623 -0.583530 -0.061195  ...  0.002652  0.023774 -0.007729   \n",
              "1    -4.853894 -5.449297  0.604696  ...  0.185167  0.087761  0.058403   \n",
              "2     0.011724 -0.074278  0.295060  ... -0.106116 -0.116623 -0.004392   \n",
              "3    -0.279108 -0.062008  0.453530  ...  0.017760  0.042083  0.017204   \n",
              "4     0.298536 -0.632671 -0.046335  ...  0.033637  0.054150  0.051159   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "4138  0.138004  0.183987  0.713666  ... -0.419539 -0.059336 -0.254646   \n",
              "4139 -0.108008  0.518320  0.090268  ...  0.104137 -0.063511  0.099590   \n",
              "4140 -0.452384  1.554877 -0.544347  ...  0.349073  0.343446 -0.404126   \n",
              "4141  0.529717 -0.194253  0.237860  ...  0.336364 -0.179108  0.174349   \n",
              "4142  0.106316 -0.181107 -0.102531  ... -0.094158  0.085157 -0.071463   \n",
              "\n",
              "           513       514       515       516       517       518       519  \n",
              "0    -0.011972  0.029302 -0.035175  0.024119  0.017398  0.022221 -0.006849  \n",
              "1     0.112367 -0.014748  0.195350 -0.123204  0.173635  0.070424  0.027614  \n",
              "2    -0.148935 -0.113039  0.227284 -0.095412 -0.058572  0.061757  0.256509  \n",
              "3    -0.010017 -0.027121  0.043902  0.038127  0.005259 -0.063878  0.016864  \n",
              "4    -0.016397 -0.028229 -0.023845 -0.040030 -0.055646 -0.020364  0.024727  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "4138 -0.040410 -0.164844  0.815406  0.671009 -0.376689 -0.560336 -0.078880  \n",
              "4139 -0.052728  0.021492  0.178274 -0.063507  0.030388 -0.025215  0.080261  \n",
              "4140  0.802472 -0.964902 -0.072082  0.977557  0.324235 -0.287580 -0.315314  \n",
              "4141  0.133407  0.140846  0.106979 -0.262924  0.167895  0.053946 -0.155764  \n",
              "4142  0.295983 -0.004245  0.076728 -0.077094 -0.106704 -0.166071 -0.207107  \n",
              "\n",
              "[4143 rows x 520 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37c6a807-86dd-4a63-93c2-c8ef2f0f3e06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "      <th>513</th>\n",
              "      <th>514</th>\n",
              "      <th>515</th>\n",
              "      <th>516</th>\n",
              "      <th>517</th>\n",
              "      <th>518</th>\n",
              "      <th>519</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.163556</td>\n",
              "      <td>1.354492</td>\n",
              "      <td>0.122609</td>\n",
              "      <td>0.614129</td>\n",
              "      <td>-0.325644</td>\n",
              "      <td>-0.765679</td>\n",
              "      <td>-0.197722</td>\n",
              "      <td>0.345623</td>\n",
              "      <td>-0.583530</td>\n",
              "      <td>-0.061195</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002652</td>\n",
              "      <td>0.023774</td>\n",
              "      <td>-0.007729</td>\n",
              "      <td>-0.011972</td>\n",
              "      <td>0.029302</td>\n",
              "      <td>-0.035175</td>\n",
              "      <td>0.024119</td>\n",
              "      <td>0.017398</td>\n",
              "      <td>0.022221</td>\n",
              "      <td>-0.006849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.944611</td>\n",
              "      <td>-1.853034</td>\n",
              "      <td>-3.423569</td>\n",
              "      <td>-3.943277</td>\n",
              "      <td>-3.041524</td>\n",
              "      <td>3.619496</td>\n",
              "      <td>-3.783854</td>\n",
              "      <td>-4.853894</td>\n",
              "      <td>-5.449297</td>\n",
              "      <td>0.604696</td>\n",
              "      <td>...</td>\n",
              "      <td>0.185167</td>\n",
              "      <td>0.087761</td>\n",
              "      <td>0.058403</td>\n",
              "      <td>0.112367</td>\n",
              "      <td>-0.014748</td>\n",
              "      <td>0.195350</td>\n",
              "      <td>-0.123204</td>\n",
              "      <td>0.173635</td>\n",
              "      <td>0.070424</td>\n",
              "      <td>0.027614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.424726</td>\n",
              "      <td>1.074610</td>\n",
              "      <td>-0.091547</td>\n",
              "      <td>0.004458</td>\n",
              "      <td>-0.401874</td>\n",
              "      <td>-0.567940</td>\n",
              "      <td>-0.354899</td>\n",
              "      <td>0.011724</td>\n",
              "      <td>-0.074278</td>\n",
              "      <td>0.295060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.106116</td>\n",
              "      <td>-0.116623</td>\n",
              "      <td>-0.004392</td>\n",
              "      <td>-0.148935</td>\n",
              "      <td>-0.113039</td>\n",
              "      <td>0.227284</td>\n",
              "      <td>-0.095412</td>\n",
              "      <td>-0.058572</td>\n",
              "      <td>0.061757</td>\n",
              "      <td>0.256509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.785259</td>\n",
              "      <td>0.864062</td>\n",
              "      <td>0.235106</td>\n",
              "      <td>0.025431</td>\n",
              "      <td>0.331659</td>\n",
              "      <td>0.115276</td>\n",
              "      <td>-0.176223</td>\n",
              "      <td>-0.279108</td>\n",
              "      <td>-0.062008</td>\n",
              "      <td>0.453530</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017760</td>\n",
              "      <td>0.042083</td>\n",
              "      <td>0.017204</td>\n",
              "      <td>-0.010017</td>\n",
              "      <td>-0.027121</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.038127</td>\n",
              "      <td>0.005259</td>\n",
              "      <td>-0.063878</td>\n",
              "      <td>0.016864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-3.167082</td>\n",
              "      <td>1.337177</td>\n",
              "      <td>0.047686</td>\n",
              "      <td>0.561414</td>\n",
              "      <td>-0.369034</td>\n",
              "      <td>-0.765479</td>\n",
              "      <td>-0.196355</td>\n",
              "      <td>0.298536</td>\n",
              "      <td>-0.632671</td>\n",
              "      <td>-0.046335</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033637</td>\n",
              "      <td>0.054150</td>\n",
              "      <td>0.051159</td>\n",
              "      <td>-0.016397</td>\n",
              "      <td>-0.028229</td>\n",
              "      <td>-0.023845</td>\n",
              "      <td>-0.040030</td>\n",
              "      <td>-0.055646</td>\n",
              "      <td>-0.020364</td>\n",
              "      <td>0.024727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4138</th>\n",
              "      <td>-1.446324</td>\n",
              "      <td>0.642952</td>\n",
              "      <td>-0.330377</td>\n",
              "      <td>-0.011503</td>\n",
              "      <td>-0.000712</td>\n",
              "      <td>-0.501163</td>\n",
              "      <td>0.366723</td>\n",
              "      <td>0.138004</td>\n",
              "      <td>0.183987</td>\n",
              "      <td>0.713666</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.419539</td>\n",
              "      <td>-0.059336</td>\n",
              "      <td>-0.254646</td>\n",
              "      <td>-0.040410</td>\n",
              "      <td>-0.164844</td>\n",
              "      <td>0.815406</td>\n",
              "      <td>0.671009</td>\n",
              "      <td>-0.376689</td>\n",
              "      <td>-0.560336</td>\n",
              "      <td>-0.078880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4139</th>\n",
              "      <td>-0.368333</td>\n",
              "      <td>0.016102</td>\n",
              "      <td>0.309881</td>\n",
              "      <td>0.342469</td>\n",
              "      <td>-0.103763</td>\n",
              "      <td>-0.023977</td>\n",
              "      <td>0.059648</td>\n",
              "      <td>-0.108008</td>\n",
              "      <td>0.518320</td>\n",
              "      <td>0.090268</td>\n",
              "      <td>...</td>\n",
              "      <td>0.104137</td>\n",
              "      <td>-0.063511</td>\n",
              "      <td>0.099590</td>\n",
              "      <td>-0.052728</td>\n",
              "      <td>0.021492</td>\n",
              "      <td>0.178274</td>\n",
              "      <td>-0.063507</td>\n",
              "      <td>0.030388</td>\n",
              "      <td>-0.025215</td>\n",
              "      <td>0.080261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4140</th>\n",
              "      <td>0.889479</td>\n",
              "      <td>-0.901727</td>\n",
              "      <td>2.048592</td>\n",
              "      <td>0.134772</td>\n",
              "      <td>-0.032090</td>\n",
              "      <td>0.193295</td>\n",
              "      <td>0.155847</td>\n",
              "      <td>-0.452384</td>\n",
              "      <td>1.554877</td>\n",
              "      <td>-0.544347</td>\n",
              "      <td>...</td>\n",
              "      <td>0.349073</td>\n",
              "      <td>0.343446</td>\n",
              "      <td>-0.404126</td>\n",
              "      <td>0.802472</td>\n",
              "      <td>-0.964902</td>\n",
              "      <td>-0.072082</td>\n",
              "      <td>0.977557</td>\n",
              "      <td>0.324235</td>\n",
              "      <td>-0.287580</td>\n",
              "      <td>-0.315314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4141</th>\n",
              "      <td>-1.755179</td>\n",
              "      <td>0.572071</td>\n",
              "      <td>0.117253</td>\n",
              "      <td>0.273678</td>\n",
              "      <td>-0.116884</td>\n",
              "      <td>-0.404077</td>\n",
              "      <td>-0.023015</td>\n",
              "      <td>0.529717</td>\n",
              "      <td>-0.194253</td>\n",
              "      <td>0.237860</td>\n",
              "      <td>...</td>\n",
              "      <td>0.336364</td>\n",
              "      <td>-0.179108</td>\n",
              "      <td>0.174349</td>\n",
              "      <td>0.133407</td>\n",
              "      <td>0.140846</td>\n",
              "      <td>0.106979</td>\n",
              "      <td>-0.262924</td>\n",
              "      <td>0.167895</td>\n",
              "      <td>0.053946</td>\n",
              "      <td>-0.155764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4142</th>\n",
              "      <td>12.216736</td>\n",
              "      <td>14.041053</td>\n",
              "      <td>-0.638560</td>\n",
              "      <td>0.219674</td>\n",
              "      <td>0.336044</td>\n",
              "      <td>-0.271704</td>\n",
              "      <td>-0.013033</td>\n",
              "      <td>0.106316</td>\n",
              "      <td>-0.181107</td>\n",
              "      <td>-0.102531</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.094158</td>\n",
              "      <td>0.085157</td>\n",
              "      <td>-0.071463</td>\n",
              "      <td>0.295983</td>\n",
              "      <td>-0.004245</td>\n",
              "      <td>0.076728</td>\n",
              "      <td>-0.077094</td>\n",
              "      <td>-0.106704</td>\n",
              "      <td>-0.166071</td>\n",
              "      <td>-0.207107</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4143 rows Ã— 520 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37c6a807-86dd-4a63-93c2-c8ef2f0f3e06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37c6a807-86dd-4a63-93c2-c8ef2f0f3e06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37c6a807-86dd-4a63-93c2-c8ef2f0f3e06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGxnU0pcXjQ7"
      },
      "outputs": [],
      "source": [
        "df.insert(no_of_features, 'Label', y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORsyMbinwWvS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "e2eecb87-ec0e-4195-89f4-c3f3ba4d8f40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0          1         2         3         4         5         6  \\\n",
              "0     -3.163556   1.354492  0.122609  0.614129 -0.325644 -0.765679 -0.197722   \n",
              "1      2.944611  -1.853034 -3.423569 -3.943277 -3.041524  3.619496 -3.783854   \n",
              "2     -2.424726   1.074610 -0.091547  0.004458 -0.401874 -0.567940 -0.354899   \n",
              "3     -1.785259   0.864062  0.235106  0.025431  0.331659  0.115276 -0.176223   \n",
              "4     -3.167082   1.337177  0.047686  0.561414 -0.369034 -0.765479 -0.196355   \n",
              "...         ...        ...       ...       ...       ...       ...       ...   \n",
              "4138  -1.446324   0.642952 -0.330377 -0.011503 -0.000712 -0.501163  0.366723   \n",
              "4139  -0.368333   0.016102  0.309881  0.342469 -0.103763 -0.023977  0.059648   \n",
              "4140   0.889479  -0.901727  2.048592  0.134772 -0.032090  0.193295  0.155847   \n",
              "4141  -1.755179   0.572071  0.117253  0.273678 -0.116884 -0.404077 -0.023015   \n",
              "4142  12.216736  14.041053 -0.638560  0.219674  0.336044 -0.271704 -0.013033   \n",
              "\n",
              "             7         8         9  ...       511       512       513  \\\n",
              "0     0.345623 -0.583530 -0.061195  ...  0.023774 -0.007729 -0.011972   \n",
              "1    -4.853894 -5.449297  0.604696  ...  0.087761  0.058403  0.112367   \n",
              "2     0.011724 -0.074278  0.295060  ... -0.116623 -0.004392 -0.148935   \n",
              "3    -0.279108 -0.062008  0.453530  ...  0.042083  0.017204 -0.010017   \n",
              "4     0.298536 -0.632671 -0.046335  ...  0.054150  0.051159 -0.016397   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "4138  0.138004  0.183987  0.713666  ... -0.059336 -0.254646 -0.040410   \n",
              "4139 -0.108008  0.518320  0.090268  ... -0.063511  0.099590 -0.052728   \n",
              "4140 -0.452384  1.554877 -0.544347  ...  0.343446 -0.404126  0.802472   \n",
              "4141  0.529717 -0.194253  0.237860  ... -0.179108  0.174349  0.133407   \n",
              "4142  0.106316 -0.181107 -0.102531  ...  0.085157 -0.071463  0.295983   \n",
              "\n",
              "           514       515       516       517       518       519  Label  \n",
              "0     0.029302 -0.035175  0.024119  0.017398  0.022221 -0.006849    1.0  \n",
              "1    -0.014748  0.195350 -0.123204  0.173635  0.070424  0.027614   -1.0  \n",
              "2    -0.113039  0.227284 -0.095412 -0.058572  0.061757  0.256509   -1.0  \n",
              "3    -0.027121  0.043902  0.038127  0.005259 -0.063878  0.016864   -1.0  \n",
              "4    -0.028229 -0.023845 -0.040030 -0.055646 -0.020364  0.024727   -1.0  \n",
              "...        ...       ...       ...       ...       ...       ...    ...  \n",
              "4138 -0.164844  0.815406  0.671009 -0.376689 -0.560336 -0.078880   -1.0  \n",
              "4139  0.021492  0.178274 -0.063507  0.030388 -0.025215  0.080261    1.0  \n",
              "4140 -0.964902 -0.072082  0.977557  0.324235 -0.287580 -0.315314    1.0  \n",
              "4141  0.140846  0.106979 -0.262924  0.167895  0.053946 -0.155764   -1.0  \n",
              "4142 -0.004245  0.076728 -0.077094 -0.106704 -0.166071 -0.207107    1.0  \n",
              "\n",
              "[4143 rows x 521 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c993602c-415f-485e-ae2e-c102cc1f0446\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "      <th>513</th>\n",
              "      <th>514</th>\n",
              "      <th>515</th>\n",
              "      <th>516</th>\n",
              "      <th>517</th>\n",
              "      <th>518</th>\n",
              "      <th>519</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.163556</td>\n",
              "      <td>1.354492</td>\n",
              "      <td>0.122609</td>\n",
              "      <td>0.614129</td>\n",
              "      <td>-0.325644</td>\n",
              "      <td>-0.765679</td>\n",
              "      <td>-0.197722</td>\n",
              "      <td>0.345623</td>\n",
              "      <td>-0.583530</td>\n",
              "      <td>-0.061195</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023774</td>\n",
              "      <td>-0.007729</td>\n",
              "      <td>-0.011972</td>\n",
              "      <td>0.029302</td>\n",
              "      <td>-0.035175</td>\n",
              "      <td>0.024119</td>\n",
              "      <td>0.017398</td>\n",
              "      <td>0.022221</td>\n",
              "      <td>-0.006849</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.944611</td>\n",
              "      <td>-1.853034</td>\n",
              "      <td>-3.423569</td>\n",
              "      <td>-3.943277</td>\n",
              "      <td>-3.041524</td>\n",
              "      <td>3.619496</td>\n",
              "      <td>-3.783854</td>\n",
              "      <td>-4.853894</td>\n",
              "      <td>-5.449297</td>\n",
              "      <td>0.604696</td>\n",
              "      <td>...</td>\n",
              "      <td>0.087761</td>\n",
              "      <td>0.058403</td>\n",
              "      <td>0.112367</td>\n",
              "      <td>-0.014748</td>\n",
              "      <td>0.195350</td>\n",
              "      <td>-0.123204</td>\n",
              "      <td>0.173635</td>\n",
              "      <td>0.070424</td>\n",
              "      <td>0.027614</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.424726</td>\n",
              "      <td>1.074610</td>\n",
              "      <td>-0.091547</td>\n",
              "      <td>0.004458</td>\n",
              "      <td>-0.401874</td>\n",
              "      <td>-0.567940</td>\n",
              "      <td>-0.354899</td>\n",
              "      <td>0.011724</td>\n",
              "      <td>-0.074278</td>\n",
              "      <td>0.295060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.116623</td>\n",
              "      <td>-0.004392</td>\n",
              "      <td>-0.148935</td>\n",
              "      <td>-0.113039</td>\n",
              "      <td>0.227284</td>\n",
              "      <td>-0.095412</td>\n",
              "      <td>-0.058572</td>\n",
              "      <td>0.061757</td>\n",
              "      <td>0.256509</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.785259</td>\n",
              "      <td>0.864062</td>\n",
              "      <td>0.235106</td>\n",
              "      <td>0.025431</td>\n",
              "      <td>0.331659</td>\n",
              "      <td>0.115276</td>\n",
              "      <td>-0.176223</td>\n",
              "      <td>-0.279108</td>\n",
              "      <td>-0.062008</td>\n",
              "      <td>0.453530</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042083</td>\n",
              "      <td>0.017204</td>\n",
              "      <td>-0.010017</td>\n",
              "      <td>-0.027121</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.038127</td>\n",
              "      <td>0.005259</td>\n",
              "      <td>-0.063878</td>\n",
              "      <td>0.016864</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-3.167082</td>\n",
              "      <td>1.337177</td>\n",
              "      <td>0.047686</td>\n",
              "      <td>0.561414</td>\n",
              "      <td>-0.369034</td>\n",
              "      <td>-0.765479</td>\n",
              "      <td>-0.196355</td>\n",
              "      <td>0.298536</td>\n",
              "      <td>-0.632671</td>\n",
              "      <td>-0.046335</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054150</td>\n",
              "      <td>0.051159</td>\n",
              "      <td>-0.016397</td>\n",
              "      <td>-0.028229</td>\n",
              "      <td>-0.023845</td>\n",
              "      <td>-0.040030</td>\n",
              "      <td>-0.055646</td>\n",
              "      <td>-0.020364</td>\n",
              "      <td>0.024727</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4138</th>\n",
              "      <td>-1.446324</td>\n",
              "      <td>0.642952</td>\n",
              "      <td>-0.330377</td>\n",
              "      <td>-0.011503</td>\n",
              "      <td>-0.000712</td>\n",
              "      <td>-0.501163</td>\n",
              "      <td>0.366723</td>\n",
              "      <td>0.138004</td>\n",
              "      <td>0.183987</td>\n",
              "      <td>0.713666</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059336</td>\n",
              "      <td>-0.254646</td>\n",
              "      <td>-0.040410</td>\n",
              "      <td>-0.164844</td>\n",
              "      <td>0.815406</td>\n",
              "      <td>0.671009</td>\n",
              "      <td>-0.376689</td>\n",
              "      <td>-0.560336</td>\n",
              "      <td>-0.078880</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4139</th>\n",
              "      <td>-0.368333</td>\n",
              "      <td>0.016102</td>\n",
              "      <td>0.309881</td>\n",
              "      <td>0.342469</td>\n",
              "      <td>-0.103763</td>\n",
              "      <td>-0.023977</td>\n",
              "      <td>0.059648</td>\n",
              "      <td>-0.108008</td>\n",
              "      <td>0.518320</td>\n",
              "      <td>0.090268</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.063511</td>\n",
              "      <td>0.099590</td>\n",
              "      <td>-0.052728</td>\n",
              "      <td>0.021492</td>\n",
              "      <td>0.178274</td>\n",
              "      <td>-0.063507</td>\n",
              "      <td>0.030388</td>\n",
              "      <td>-0.025215</td>\n",
              "      <td>0.080261</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4140</th>\n",
              "      <td>0.889479</td>\n",
              "      <td>-0.901727</td>\n",
              "      <td>2.048592</td>\n",
              "      <td>0.134772</td>\n",
              "      <td>-0.032090</td>\n",
              "      <td>0.193295</td>\n",
              "      <td>0.155847</td>\n",
              "      <td>-0.452384</td>\n",
              "      <td>1.554877</td>\n",
              "      <td>-0.544347</td>\n",
              "      <td>...</td>\n",
              "      <td>0.343446</td>\n",
              "      <td>-0.404126</td>\n",
              "      <td>0.802472</td>\n",
              "      <td>-0.964902</td>\n",
              "      <td>-0.072082</td>\n",
              "      <td>0.977557</td>\n",
              "      <td>0.324235</td>\n",
              "      <td>-0.287580</td>\n",
              "      <td>-0.315314</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4141</th>\n",
              "      <td>-1.755179</td>\n",
              "      <td>0.572071</td>\n",
              "      <td>0.117253</td>\n",
              "      <td>0.273678</td>\n",
              "      <td>-0.116884</td>\n",
              "      <td>-0.404077</td>\n",
              "      <td>-0.023015</td>\n",
              "      <td>0.529717</td>\n",
              "      <td>-0.194253</td>\n",
              "      <td>0.237860</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.179108</td>\n",
              "      <td>0.174349</td>\n",
              "      <td>0.133407</td>\n",
              "      <td>0.140846</td>\n",
              "      <td>0.106979</td>\n",
              "      <td>-0.262924</td>\n",
              "      <td>0.167895</td>\n",
              "      <td>0.053946</td>\n",
              "      <td>-0.155764</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4142</th>\n",
              "      <td>12.216736</td>\n",
              "      <td>14.041053</td>\n",
              "      <td>-0.638560</td>\n",
              "      <td>0.219674</td>\n",
              "      <td>0.336044</td>\n",
              "      <td>-0.271704</td>\n",
              "      <td>-0.013033</td>\n",
              "      <td>0.106316</td>\n",
              "      <td>-0.181107</td>\n",
              "      <td>-0.102531</td>\n",
              "      <td>...</td>\n",
              "      <td>0.085157</td>\n",
              "      <td>-0.071463</td>\n",
              "      <td>0.295983</td>\n",
              "      <td>-0.004245</td>\n",
              "      <td>0.076728</td>\n",
              "      <td>-0.077094</td>\n",
              "      <td>-0.106704</td>\n",
              "      <td>-0.166071</td>\n",
              "      <td>-0.207107</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4143 rows Ã— 521 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c993602c-415f-485e-ae2e-c102cc1f0446')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c993602c-415f-485e-ae2e-c102cc1f0446 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c993602c-415f-485e-ae2e-c102cc1f0446');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W2ACNE_2fqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb9fadb-ab76-4171-c684-82b546bf850d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3314, 829)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "t1 = df.sample(frac=0.8,random_state=100)\n",
        "t2 = df.drop(t1.index)\n",
        "\n",
        "len(t1), len(t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn3XauX83iQa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "b0c6cb0f-39cd-47bc-f4e0-cb84b754b2e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "2280 -1.978141  0.589198  0.786112  0.271875 -0.411723  0.117441  0.130675   \n",
              "2888 -1.871362  0.285709 -0.981533 -0.115179 -0.018796 -0.721802 -0.528681   \n",
              "1568  0.854090 -1.130812  2.259693  0.490170 -0.079841  0.891291 -0.176710   \n",
              "3249 -2.063370  0.763066 -1.032347 -0.833967 -0.584380 -0.616016 -0.189024   \n",
              "3765  0.351286  1.175211  1.670889  0.362812  0.747802 -1.118489 -0.348105   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "3994  0.383312  1.162218  1.751956  0.350149  0.755391 -1.152585 -0.355943   \n",
              "2385  0.362656 -0.895914 -2.102759 -1.578320 -0.215866 -0.326712 -1.613771   \n",
              "3458 -2.162007  0.650815  0.603762  0.398812 -0.230085 -0.527576  0.056730   \n",
              "3606 -0.439156 -0.046317  0.821813  0.716538  0.521965  0.344686  0.783902   \n",
              "1946 -3.168699  1.350222  0.110570  0.605987 -0.338327 -0.776210 -0.185288   \n",
              "\n",
              "             7         8         9  ...       511       512       513  \\\n",
              "2280 -0.566682 -0.067313  0.297906  ...  0.184632 -0.342961 -0.074727   \n",
              "2888  0.484127 -0.336386 -0.556121  ...  0.071863 -0.045028  0.071242   \n",
              "1568 -1.785777  1.024067  0.235464  ...  0.595100 -0.644280  0.018915   \n",
              "3249  0.020874  0.911860  2.289687  ...  0.046234 -0.141222 -0.390948   \n",
              "3765  1.289910  1.300334  1.708132  ...  0.044485 -0.089829 -0.187399   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "3994  1.244924  1.323388  1.724567  ...  0.011967 -0.126328 -0.202446   \n",
              "2385  0.281916 -0.202043 -1.172442  ...  0.026638  0.006728 -0.016733   \n",
              "3458  0.316092 -0.112163 -0.119927  ... -0.123276 -0.019458  0.055739   \n",
              "3606  0.477981  0.280667  0.504853  ... -0.566485  1.359361 -0.226897   \n",
              "1946  0.354627 -0.595401 -0.063781  ...  0.054179  0.020682  0.014243   \n",
              "\n",
              "           514       515       516       517       518       519  Label  \n",
              "2280 -0.221977 -0.021352  0.002997  0.130308 -0.119302  0.044573   -1.0  \n",
              "2888 -0.007533 -0.049406  0.024133  0.034523 -0.067504 -0.017471    1.0  \n",
              "1568  0.647483  0.049491 -0.271779 -0.047100 -0.223357  1.060074    1.0  \n",
              "3249  0.183533 -0.053263 -0.387359 -0.214758 -0.117201 -0.009616   -1.0  \n",
              "3765 -0.019341  0.035795  0.158830 -0.022202  0.011162  0.204164   -1.0  \n",
              "...        ...       ...       ...       ...       ...       ...    ...  \n",
              "3994 -0.042679  0.067904  0.150570 -0.030854  0.029646  0.143107   -1.0  \n",
              "2385 -0.060556 -0.042009 -0.010872 -0.007981 -0.044051  0.021935    1.0  \n",
              "3458  0.019837 -0.235914 -0.005566 -0.392265  0.185622 -0.353924    1.0  \n",
              "3606 -0.054603  0.536200  0.222981 -0.203072 -0.170949  0.281726    1.0  \n",
              "1946  0.053786 -0.005625  0.028934  0.043824  0.005872 -0.061578   -1.0  \n",
              "\n",
              "[3314 rows x 521 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48776bb0-49ab-4ccf-ad69-9d5a16f7d970\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "      <th>513</th>\n",
              "      <th>514</th>\n",
              "      <th>515</th>\n",
              "      <th>516</th>\n",
              "      <th>517</th>\n",
              "      <th>518</th>\n",
              "      <th>519</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2280</th>\n",
              "      <td>-1.978141</td>\n",
              "      <td>0.589198</td>\n",
              "      <td>0.786112</td>\n",
              "      <td>0.271875</td>\n",
              "      <td>-0.411723</td>\n",
              "      <td>0.117441</td>\n",
              "      <td>0.130675</td>\n",
              "      <td>-0.566682</td>\n",
              "      <td>-0.067313</td>\n",
              "      <td>0.297906</td>\n",
              "      <td>...</td>\n",
              "      <td>0.184632</td>\n",
              "      <td>-0.342961</td>\n",
              "      <td>-0.074727</td>\n",
              "      <td>-0.221977</td>\n",
              "      <td>-0.021352</td>\n",
              "      <td>0.002997</td>\n",
              "      <td>0.130308</td>\n",
              "      <td>-0.119302</td>\n",
              "      <td>0.044573</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2888</th>\n",
              "      <td>-1.871362</td>\n",
              "      <td>0.285709</td>\n",
              "      <td>-0.981533</td>\n",
              "      <td>-0.115179</td>\n",
              "      <td>-0.018796</td>\n",
              "      <td>-0.721802</td>\n",
              "      <td>-0.528681</td>\n",
              "      <td>0.484127</td>\n",
              "      <td>-0.336386</td>\n",
              "      <td>-0.556121</td>\n",
              "      <td>...</td>\n",
              "      <td>0.071863</td>\n",
              "      <td>-0.045028</td>\n",
              "      <td>0.071242</td>\n",
              "      <td>-0.007533</td>\n",
              "      <td>-0.049406</td>\n",
              "      <td>0.024133</td>\n",
              "      <td>0.034523</td>\n",
              "      <td>-0.067504</td>\n",
              "      <td>-0.017471</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1568</th>\n",
              "      <td>0.854090</td>\n",
              "      <td>-1.130812</td>\n",
              "      <td>2.259693</td>\n",
              "      <td>0.490170</td>\n",
              "      <td>-0.079841</td>\n",
              "      <td>0.891291</td>\n",
              "      <td>-0.176710</td>\n",
              "      <td>-1.785777</td>\n",
              "      <td>1.024067</td>\n",
              "      <td>0.235464</td>\n",
              "      <td>...</td>\n",
              "      <td>0.595100</td>\n",
              "      <td>-0.644280</td>\n",
              "      <td>0.018915</td>\n",
              "      <td>0.647483</td>\n",
              "      <td>0.049491</td>\n",
              "      <td>-0.271779</td>\n",
              "      <td>-0.047100</td>\n",
              "      <td>-0.223357</td>\n",
              "      <td>1.060074</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3249</th>\n",
              "      <td>-2.063370</td>\n",
              "      <td>0.763066</td>\n",
              "      <td>-1.032347</td>\n",
              "      <td>-0.833967</td>\n",
              "      <td>-0.584380</td>\n",
              "      <td>-0.616016</td>\n",
              "      <td>-0.189024</td>\n",
              "      <td>0.020874</td>\n",
              "      <td>0.911860</td>\n",
              "      <td>2.289687</td>\n",
              "      <td>...</td>\n",
              "      <td>0.046234</td>\n",
              "      <td>-0.141222</td>\n",
              "      <td>-0.390948</td>\n",
              "      <td>0.183533</td>\n",
              "      <td>-0.053263</td>\n",
              "      <td>-0.387359</td>\n",
              "      <td>-0.214758</td>\n",
              "      <td>-0.117201</td>\n",
              "      <td>-0.009616</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3765</th>\n",
              "      <td>0.351286</td>\n",
              "      <td>1.175211</td>\n",
              "      <td>1.670889</td>\n",
              "      <td>0.362812</td>\n",
              "      <td>0.747802</td>\n",
              "      <td>-1.118489</td>\n",
              "      <td>-0.348105</td>\n",
              "      <td>1.289910</td>\n",
              "      <td>1.300334</td>\n",
              "      <td>1.708132</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044485</td>\n",
              "      <td>-0.089829</td>\n",
              "      <td>-0.187399</td>\n",
              "      <td>-0.019341</td>\n",
              "      <td>0.035795</td>\n",
              "      <td>0.158830</td>\n",
              "      <td>-0.022202</td>\n",
              "      <td>0.011162</td>\n",
              "      <td>0.204164</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3994</th>\n",
              "      <td>0.383312</td>\n",
              "      <td>1.162218</td>\n",
              "      <td>1.751956</td>\n",
              "      <td>0.350149</td>\n",
              "      <td>0.755391</td>\n",
              "      <td>-1.152585</td>\n",
              "      <td>-0.355943</td>\n",
              "      <td>1.244924</td>\n",
              "      <td>1.323388</td>\n",
              "      <td>1.724567</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011967</td>\n",
              "      <td>-0.126328</td>\n",
              "      <td>-0.202446</td>\n",
              "      <td>-0.042679</td>\n",
              "      <td>0.067904</td>\n",
              "      <td>0.150570</td>\n",
              "      <td>-0.030854</td>\n",
              "      <td>0.029646</td>\n",
              "      <td>0.143107</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2385</th>\n",
              "      <td>0.362656</td>\n",
              "      <td>-0.895914</td>\n",
              "      <td>-2.102759</td>\n",
              "      <td>-1.578320</td>\n",
              "      <td>-0.215866</td>\n",
              "      <td>-0.326712</td>\n",
              "      <td>-1.613771</td>\n",
              "      <td>0.281916</td>\n",
              "      <td>-0.202043</td>\n",
              "      <td>-1.172442</td>\n",
              "      <td>...</td>\n",
              "      <td>0.026638</td>\n",
              "      <td>0.006728</td>\n",
              "      <td>-0.016733</td>\n",
              "      <td>-0.060556</td>\n",
              "      <td>-0.042009</td>\n",
              "      <td>-0.010872</td>\n",
              "      <td>-0.007981</td>\n",
              "      <td>-0.044051</td>\n",
              "      <td>0.021935</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3458</th>\n",
              "      <td>-2.162007</td>\n",
              "      <td>0.650815</td>\n",
              "      <td>0.603762</td>\n",
              "      <td>0.398812</td>\n",
              "      <td>-0.230085</td>\n",
              "      <td>-0.527576</td>\n",
              "      <td>0.056730</td>\n",
              "      <td>0.316092</td>\n",
              "      <td>-0.112163</td>\n",
              "      <td>-0.119927</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.123276</td>\n",
              "      <td>-0.019458</td>\n",
              "      <td>0.055739</td>\n",
              "      <td>0.019837</td>\n",
              "      <td>-0.235914</td>\n",
              "      <td>-0.005566</td>\n",
              "      <td>-0.392265</td>\n",
              "      <td>0.185622</td>\n",
              "      <td>-0.353924</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3606</th>\n",
              "      <td>-0.439156</td>\n",
              "      <td>-0.046317</td>\n",
              "      <td>0.821813</td>\n",
              "      <td>0.716538</td>\n",
              "      <td>0.521965</td>\n",
              "      <td>0.344686</td>\n",
              "      <td>0.783902</td>\n",
              "      <td>0.477981</td>\n",
              "      <td>0.280667</td>\n",
              "      <td>0.504853</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.566485</td>\n",
              "      <td>1.359361</td>\n",
              "      <td>-0.226897</td>\n",
              "      <td>-0.054603</td>\n",
              "      <td>0.536200</td>\n",
              "      <td>0.222981</td>\n",
              "      <td>-0.203072</td>\n",
              "      <td>-0.170949</td>\n",
              "      <td>0.281726</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1946</th>\n",
              "      <td>-3.168699</td>\n",
              "      <td>1.350222</td>\n",
              "      <td>0.110570</td>\n",
              "      <td>0.605987</td>\n",
              "      <td>-0.338327</td>\n",
              "      <td>-0.776210</td>\n",
              "      <td>-0.185288</td>\n",
              "      <td>0.354627</td>\n",
              "      <td>-0.595401</td>\n",
              "      <td>-0.063781</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054179</td>\n",
              "      <td>0.020682</td>\n",
              "      <td>0.014243</td>\n",
              "      <td>0.053786</td>\n",
              "      <td>-0.005625</td>\n",
              "      <td>0.028934</td>\n",
              "      <td>0.043824</td>\n",
              "      <td>0.005872</td>\n",
              "      <td>-0.061578</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3314 rows Ã— 521 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48776bb0-49ab-4ccf-ad69-9d5a16f7d970')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48776bb0-49ab-4ccf-ad69-9d5a16f7d970 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48776bb0-49ab-4ccf-ad69-9d5a16f7d970');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi4VZIY10M4G"
      },
      "outputs": [],
      "source": [
        "c_t1, f_t1 = np.unique(t1['Label'], return_counts=True)\n",
        "c_t2, f_t2 = np.unique(t2['Label'], return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeVPN5Jn0vcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3732af6d-99df-4ed4-bc89-1b03b312b6e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For T1 data:\n",
            "No of samples belonging to class -1.0 is 1555\n",
            "No of samples belonging to class 1.0 is 1759\n",
            "\n",
            "For T2 data:\n",
            "No of samples belonging to class -1.0 is 378\n",
            "No of samples belonging to class 1.0 is 451\n"
          ]
        }
      ],
      "source": [
        "print(\"For T1 data:\")\n",
        "for i in range(len(c_t1)):\n",
        "  print(\"No of samples belonging to class\", c_t1[i], \"is\", f_t1[i])\n",
        "\n",
        "print(\"\\nFor T2 data:\")\n",
        "for i in range(len(c_t2)):\n",
        "  print(\"No of samples belonging to class\", c_t2[i], \"is\", f_t2[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rK9sOsqw6Kg"
      },
      "source": [
        "Both the datasets T1 and T2 have similar class label proportions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Fjeuz-42i3O"
      },
      "outputs": [],
      "source": [
        "cols = list(np.arange(0, no_of_features))\n",
        "X_train = t1[t1.columns[cols]].to_numpy()\n",
        "X_test = t2[t2.columns[cols]].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohOYD2Ob2sBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8528c8a-d232-4c83-8786-ae681ca12bf0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.9781413 ,  0.58919837,  0.78611235, ...,  0.13030788,\n",
              "        -0.11930248,  0.04457285],\n",
              "       [-1.8713622 ,  0.28570865, -0.98153328, ...,  0.0345233 ,\n",
              "        -0.06750414, -0.01747109],\n",
              "       [ 0.85409033, -1.13081209,  2.25969285, ..., -0.04709963,\n",
              "        -0.22335692,  1.06007386],\n",
              "       ...,\n",
              "       [-2.16200668,  0.65081516,  0.60376202, ..., -0.39226525,\n",
              "         0.18562227, -0.35392444],\n",
              "       [-0.43915561, -0.04631684,  0.82181315, ..., -0.20307236,\n",
              "        -0.17094852,  0.28172559],\n",
              "       [-3.16869891,  1.35022169,  0.1105697 , ...,  0.04382425,\n",
              "         0.00587182, -0.06157772]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBGzdCWx3HwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97eca31-570e-48c0-b86c-e6a69d64a13a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.42472556e+00,  1.07460981e+00, -9.15473283e-02, ...,\n",
              "        -5.85720272e-02,  6.17565303e-02,  2.56509028e-01],\n",
              "       [-1.78525920e+00,  8.64062096e-01,  2.35105900e-01, ...,\n",
              "         5.25877254e-03, -6.38777125e-02,  1.68644332e-02],\n",
              "       [-3.15131198e+00,  1.34124458e+00,  1.26068021e-01, ...,\n",
              "        -3.77893550e-02,  1.20958428e-02, -2.41914836e-03],\n",
              "       ...,\n",
              "       [ 1.58203966e-01, -3.61287969e-01,  2.63822836e+00, ...,\n",
              "        -1.12348305e-01,  1.57989282e-03, -2.51199686e-01],\n",
              "       [-2.34334168e+00,  3.16280251e-01, -1.09120098e+00, ...,\n",
              "         1.82390843e-02, -1.00974943e-01,  1.49627042e-01],\n",
              "       [-1.44632430e+00,  6.42951553e-01, -3.30377327e-01, ...,\n",
              "        -3.76688901e-01, -5.60335817e-01, -7.88800062e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtY_m1Cq24Vf"
      },
      "outputs": [],
      "source": [
        "response_cols = [no_of_features]\n",
        "y_train = t1[t1.columns[response_cols]].to_numpy()\n",
        "y_test = t2[t2.columns[response_cols]].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilxu8gND2_jg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d76b31-9877-4542-c210-ca7eb6f65162"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       ...,\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZV318yy3AbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0abd46a-e273-4adc-dd44-be4f787e01f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [ 1.],\n",
              "       [-1.],\n",
              "       [-1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sIQlbXf4DLX"
      },
      "source": [
        "### Answer d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utHK2b8cl4A2"
      },
      "outputs": [],
      "source": [
        "def metrics_for_evaluation(model, X, y):\n",
        "    y_pred = model.predict(X)\n",
        "    confusion_matrix_values = confusion_matrix(y_true=y,y_pred=y_pred)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    precision = precision_score(y, y_pred)\n",
        "    recall = recall_score(y, y_pred)\n",
        "    f1 = f1_score(y, y_pred)\n",
        "    sensitivity = confusion_matrix_values[0,0]/(confusion_matrix_values[0,0]+confusion_matrix_values[0,1])\n",
        "    specificity = confusion_matrix_values[1,1]/(confusion_matrix_values[1,0]+confusion_matrix_values[1,1])\n",
        "    return accuracy, precision, recall, f1, sensitivity, specificity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part i)"
      ],
      "metadata": {
        "id": "E6PR8Gr9Q4NS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPWdqHYId87N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621c6f86-0a41-4a21-a41c-f06cb9f5e1ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression with L2 regularizer\n",
            "\n",
            "For train data:\n",
            "Accuracy = 0.9330114665057333\n",
            "Precision = 0.9178901576943991\n",
            "Recall = 0.9596361569073337\n",
            "F1 Score = 0.9382990550305725\n",
            "Sensitivity = 0.9028938906752412\n",
            "Specitivity = 0.9596361569073337\n",
            "\n",
            "For test data:\n",
            "Accuracy = 0.8950542822677925\n",
            "Precision = 0.8888888888888888\n",
            "Recall = 0.9223946784922394\n",
            "F1 Score = 0.9053318824809575\n",
            "Sensitivity = 0.8624338624338624\n",
            "Specitivity = 0.9223946784922394\n"
          ]
        }
      ],
      "source": [
        "logistic_l2 = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
        "logistic_l2_param_grid = {'C': np.array([0.01, 0.1, 1, 10, 100])}\n",
        "logistic_l2_cv = GridSearchCV(logistic_l2, logistic_l2_param_grid, cv=5, n_jobs=multiprocessing.cpu_count())\n",
        "logistic_l2_cv.fit(X_train, y_train)\n",
        "\n",
        "acc_train, prec_train, rec_train, f_train, sen_train, spec_train=metrics_for_evaluation(logistic_l2_cv, X_train, y_train)\n",
        "acc_test, prec_test, rec_test, f_test, sen_test, spec_test=metrics_for_evaluation(logistic_l2_cv, X_test, y_test)\n",
        "\n",
        "print(\"Logistic regression with L2 regularizer\")\n",
        "\n",
        "print(\"\\nFor train data:\")\n",
        "print(\"Accuracy =\", acc_train)\n",
        "print(\"Precision =\", prec_train)\n",
        "print(\"Recall =\", rec_train)\n",
        "print(\"F1 Score =\", f_train)\n",
        "print(\"Sensitivity =\", sen_train)\n",
        "print(\"Specitivity =\", spec_train)\n",
        "\n",
        "print(\"\\nFor test data:\")\n",
        "print(\"Accuracy =\", acc_test)\n",
        "print(\"Precision =\", prec_test)\n",
        "print(\"Recall =\", rec_test)\n",
        "print(\"F1 Score =\", f_test)\n",
        "print(\"Sensitivity =\", sen_test)\n",
        "print(\"Specitivity =\", spec_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dChKNub-eBaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d710e86-38ba-4cca-ff60-6a0a8ae2a835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soft-margin SVM with L2 regularizer\n",
            "\n",
            "For train data:\n",
            "Accuracy = 0.9417622208811104\n",
            "Precision = 0.926006528835691\n",
            "Recall = 0.9675952245594087\n",
            "F1 Score = 0.9463441757019738\n",
            "Sensitivity = 0.912540192926045\n",
            "Specitivity = 0.9675952245594087\n",
            "\n",
            "For test data:\n",
            "Accuracy = 0.8986731001206273\n",
            "Precision = 0.8997821350762527\n",
            "Recall = 0.9157427937915743\n",
            "F1 Score = 0.9076923076923077\n",
            "Sensitivity = 0.8783068783068783\n",
            "Specitivity = 0.9157427937915743\n"
          ]
        }
      ],
      "source": [
        "svm_l2 = SVC(kernel='linear')\n",
        "svm_l2_param_grid = {'C':np.array([0.01, 0.1, 1, 10, 100])}\n",
        "svm_l2_cv = GridSearchCV(svm_l2, svm_l2_param_grid, cv=5,n_jobs=multiprocessing.cpu_count())\n",
        "svm_l2_cv.fit(X_train,y_train)\n",
        "\n",
        "acc_train, prec_train, rec_train, f_train, sen_train, spec_train=metrics_for_evaluation(svm_l2_cv, X_train, y_train)\n",
        "acc_test, prec_test, rec_test, f_test, sen_test, spec_test=metrics_for_evaluation(svm_l2_cv, X_test, y_test)\n",
        "\n",
        "print(\"Soft-margin SVM with L2 regularizer\")\n",
        "\n",
        "print(\"\\nFor train data:\")\n",
        "print(\"Accuracy =\", acc_train)\n",
        "print(\"Precision =\", prec_train)\n",
        "print(\"Recall =\", rec_train)\n",
        "print(\"F1 Score =\", f_train)\n",
        "print(\"Sensitivity =\", sen_train)\n",
        "print(\"Specitivity =\", spec_train)\n",
        "\n",
        "print(\"\\nFor test data:\")\n",
        "print(\"Accuracy =\", acc_test)\n",
        "print(\"Precision =\", prec_test)\n",
        "print(\"Recall =\", rec_test)\n",
        "print(\"F1 Score =\", f_test)\n",
        "print(\"Sensitivity =\", sen_test)\n",
        "print(\"Specitivity =\", spec_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV0fU1VGeEJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16f2bbd-5802-4d67-9fd8-b3d07b4e8a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soft-margin SVM with L1 regularizer\n",
            "\n",
            "For train data:\n",
            "Accuracy = 0.9269764634882317\n",
            "Precision = 0.9263631253513209\n",
            "Recall = 0.9368959636156907\n",
            "F1 Score = 0.93159977388355\n",
            "Sensitivity = 0.9157556270096463\n",
            "Specitivity = 0.9368959636156907\n",
            "\n",
            "For test data:\n",
            "Accuracy = 0.887816646562123\n",
            "Precision = 0.9049773755656109\n",
            "Recall = 0.8869179600886918\n",
            "F1 Score = 0.8958566629339305\n",
            "Sensitivity = 0.8888888888888888\n",
            "Specitivity = 0.8869179600886918\n"
          ]
        }
      ],
      "source": [
        "svm_l1 = LinearSVC(penalty='l1', dual=False, class_weight = 'balanced')\n",
        "svm_l1_param_grid = {'C': np.array([0.01, 0.1, 1, 10, 100])}\n",
        "svm_l1_cv = GridSearchCV(svm_l1, svm_l1_param_grid, cv=5,n_jobs=multiprocessing.cpu_count())\n",
        "svm_l1_cv.fit(X_train,y_train)\n",
        "\n",
        "acc_train, prec_train, rec_train, f_train, sen_train, spec_train=metrics_for_evaluation(svm_l1_cv, X_train, y_train)\n",
        "acc_test, prec_test, rec_test, f_test, sen_test, spec_test=metrics_for_evaluation(svm_l1_cv, X_test, y_test)\n",
        "\n",
        "print(\"Soft-margin SVM with L1 regularizer\")\n",
        "\n",
        "print(\"\\nFor train data:\")\n",
        "print(\"Accuracy =\", acc_train)\n",
        "print(\"Precision =\", prec_train)\n",
        "print(\"Recall =\", rec_train)\n",
        "print(\"F1 Score =\", f_train)\n",
        "print(\"Sensitivity =\", sen_train)\n",
        "print(\"Specitivity =\", spec_train)\n",
        "\n",
        "print(\"\\nFor test data:\")\n",
        "print(\"Accuracy =\", acc_test)\n",
        "print(\"Precision =\", prec_test)\n",
        "print(\"Recall =\", rec_test)\n",
        "print(\"F1 Score =\", f_test)\n",
        "print(\"Sensitivity =\", sen_test)\n",
        "print(\"Specitivity =\", spec_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ez0vNyGeG0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0320d37b-0c30-4877-9c51-97b9130678fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel SVM with RBF kernel\n",
            "\n",
            "For train data:\n",
            "Accuracy = 0.9378394689197345\n",
            "Precision = 0.9136920618007459\n",
            "Recall = 0.9749857873791927\n",
            "F1 Score = 0.9433443344334433\n",
            "Sensitivity = 0.8958199356913183\n",
            "Specitivity = 0.9749857873791927\n",
            "\n",
            "For test data:\n",
            "Accuracy = 0.8854041013268998\n",
            "Precision = 0.8517786561264822\n",
            "Recall = 0.9556541019955654\n",
            "F1 Score = 0.9007314524555903\n",
            "Sensitivity = 0.8015873015873016\n",
            "Specitivity = 0.9556541019955654\n"
          ]
        }
      ],
      "source": [
        "svm_rbf = SVC(kernel='rbf')\n",
        "svm_rbf_param_grid = {'gamma': np.array([ 0.01, 0.1, 1, 10, 100])}\n",
        "svm_rbf_cv = GridSearchCV(svm_rbf, svm_rbf_param_grid, cv=5,n_jobs=multiprocessing.cpu_count())\n",
        "svm_rbf_cv.fit(X_train,y_train)\n",
        "\n",
        "acc_train, prec_train, rec_train, f_train, sen_train, spec_train=metrics_for_evaluation(svm_rbf_cv, X_train, y_train)\n",
        "acc_test, prec_test, rec_test, f_test, sen_test, spec_test=metrics_for_evaluation(svm_rbf_cv, X_test, y_test)\n",
        "\n",
        "print(\"Kernel SVM with RBF kernel\")\n",
        "\n",
        "print(\"\\nFor train data:\")\n",
        "print(\"Accuracy =\", acc_train)\n",
        "print(\"Precision =\", prec_train)\n",
        "print(\"Recall =\", rec_train)\n",
        "print(\"F1 Score =\", f_train)\n",
        "print(\"Sensitivity =\", sen_train)\n",
        "print(\"Specitivity =\", spec_train)\n",
        "\n",
        "print(\"\\nFor test data:\")\n",
        "print(\"Accuracy =\", acc_test)\n",
        "print(\"Precision =\", prec_test)\n",
        "print(\"Recall =\", rec_test)\n",
        "print(\"F1 Score =\", f_test)\n",
        "print(\"Sensitivity =\", sen_test)\n",
        "print(\"Specitivity =\", spec_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiv7z-lvewHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad0062c-0747-46c3-ced1-d489b42c712d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN\n",
            "\n",
            "For train data:\n",
            "Accuracy = 0.9990947495473748\n",
            "Precision = 0.9988636363636364\n",
            "Recall = 0.9994314951677089\n",
            "F1 Score = 0.9991474850809889\n",
            "Sensitivity = 0.9987138263665595\n",
            "Specitivity = 0.9994314951677089\n",
            "\n",
            "For test data:\n",
            "Accuracy = 0.8829915560916767\n",
            "Precision = 0.9022727272727272\n",
            "Recall = 0.8802660753880266\n",
            "F1 Score = 0.8911335578002244\n",
            "Sensitivity = 0.8862433862433863\n",
            "Specitivity = 0.8802660753880266\n"
          ]
        }
      ],
      "source": [
        "knn = KNeighborsClassifier()\n",
        "k_range = list(range(1, 31))\n",
        "knn_cv = GridSearchCV(knn, {'n_neighbors': k_range}, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "knn_cv.fit(X_train, y_train)\n",
        "\n",
        "acc_train, prec_train, rec_train, f_train, sen_train, spec_train=metrics_for_evaluation(knn_cv, X_train, y_train)\n",
        "acc_test, prec_test, rec_test, f_test, sen_test, spec_test=metrics_for_evaluation(knn_cv, X_test, y_test)\n",
        "\n",
        "print(\"KNN\")\n",
        "\n",
        "print(\"\\nFor train data:\")\n",
        "print(\"Accuracy =\", acc_train)\n",
        "print(\"Precision =\", prec_train)\n",
        "print(\"Recall =\", rec_train)\n",
        "print(\"F1 Score =\", f_train)\n",
        "print(\"Sensitivity =\", sen_train)\n",
        "print(\"Specitivity =\", spec_train)\n",
        "\n",
        "print(\"\\nFor test data:\")\n",
        "print(\"Accuracy =\", acc_test)\n",
        "print(\"Precision =\", prec_test)\n",
        "print(\"Recall =\", rec_test)\n",
        "print(\"F1 Score =\", f_test)\n",
        "print(\"Sensitivity =\", sen_test)\n",
        "print(\"Specitivity =\", spec_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6qxAnfSewsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df094333-597d-40d6-efe9-e78564c8b9ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree\n",
            "\n",
            "For train data:\n",
            "Accuracy = 0.9990947495473748\n",
            "Precision = 0.9988636363636364\n",
            "Recall = 0.9994314951677089\n",
            "F1 Score = 0.9991474850809889\n",
            "Sensitivity = 0.9987138263665595\n",
            "Specitivity = 0.9994314951677089\n",
            "\n",
            "For test data:\n",
            "Accuracy = 0.8311218335343787\n",
            "Precision = 0.859122401847575\n",
            "Recall = 0.8248337028824834\n",
            "F1 Score = 0.841628959276018\n",
            "Sensitivity = 0.8386243386243386\n",
            "Specitivity = 0.8248337028824834\n"
          ]
        }
      ],
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt_params = {'min_weight_fraction_leaf': np.linspace(0.0, 0.5, 11)}\n",
        "dt_cv = GridSearchCV(dt, dt_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "dt_cv.fit(X_train, y_train)\n",
        "\n",
        "acc_train, prec_train, rec_train, f_train, sen_train, spec_train=metrics_for_evaluation(dt_cv, X_train, y_train)\n",
        "acc_test, prec_test, rec_test, f_test, sen_test, spec_test=metrics_for_evaluation(dt_cv, X_test, y_test)\n",
        "\n",
        "print(\"Decision Tree\")\n",
        "\n",
        "print(\"\\nFor train data:\")\n",
        "print(\"Accuracy =\", acc_train)\n",
        "print(\"Precision =\", prec_train)\n",
        "print(\"Recall =\", rec_train)\n",
        "print(\"F1 Score =\", f_train)\n",
        "print(\"Sensitivity =\", sen_train)\n",
        "print(\"Specitivity =\", spec_train)\n",
        "\n",
        "print(\"\\nFor test data:\")\n",
        "print(\"Accuracy =\", acc_test)\n",
        "print(\"Precision =\", prec_test)\n",
        "print(\"Recall =\", rec_test)\n",
        "print(\"F1 Score =\", f_test)\n",
        "print(\"Sensitivity =\", sen_test)\n",
        "print(\"Specitivity =\", spec_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL9Y4Tdleyjg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16ce19c-e39c-4af8-b3c8-28e6b79c5ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest\n",
            "\n",
            "For train data:\n",
            "Accuracy = 0.9990947495473748\n",
            "Precision = 0.9988636363636364\n",
            "Recall = 0.9994314951677089\n",
            "F1 Score = 0.9991474850809889\n",
            "Sensitivity = 0.9987138263665595\n",
            "Specitivity = 0.9994314951677089\n",
            "\n",
            "For test data:\n",
            "Accuracy = 0.8866103739445115\n",
            "Precision = 0.8606060606060606\n",
            "Recall = 0.9445676274944568\n",
            "F1 Score = 0.9006342494714589\n",
            "Sensitivity = 0.8174603174603174\n",
            "Specitivity = 0.9445676274944568\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf_params = {'n_estimators': list(range(50, 251, 50))}\n",
        "rf_cv = GridSearchCV(rf, rf_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "rf_cv.fit(X_train, y_train)\n",
        "\n",
        "acc_train, prec_train, rec_train, f_train, sen_train, spec_train=metrics_for_evaluation(rf_cv, X_train, y_train)\n",
        "acc_test, prec_test, rec_test, f_test, sen_test, spec_test=metrics_for_evaluation(rf_cv, X_test, y_test)\n",
        "\n",
        "print(\"Random Forest\")\n",
        "\n",
        "print(\"\\nFor train data:\")\n",
        "print(\"Accuracy =\", acc_train)\n",
        "print(\"Precision =\", prec_train)\n",
        "print(\"Recall =\", rec_train)\n",
        "print(\"F1 Score =\", f_train)\n",
        "print(\"Sensitivity =\", sen_train)\n",
        "print(\"Specitivity =\", spec_train)\n",
        "\n",
        "print(\"\\nFor test data:\")\n",
        "print(\"Accuracy =\", acc_test)\n",
        "print(\"Precision =\", prec_test)\n",
        "print(\"Recall =\", rec_test)\n",
        "print(\"F1 Score =\", f_test)\n",
        "print(\"Sensitivity =\", sen_test)\n",
        "print(\"Specitivity =\", spec_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzVGmE8_d-7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e21ea4-6318-4854-dfa1-765bd50f2784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression with L1 regularizer\n",
            "\n",
            "For train data:\n",
            "Accuracy = 0.9450814725407363\n",
            "Precision = 0.9349145063430778\n",
            "Recall = 0.9636156907333713\n",
            "F1 Score = 0.9490481522956328\n",
            "Sensitivity = 0.9241157556270096\n",
            "Specitivity = 0.9636156907333713\n",
            "\n",
            "For test data:\n",
            "Accuracy = 0.8890229191797346\n",
            "Precision = 0.8980044345898004\n",
            "Recall = 0.8980044345898004\n",
            "F1 Score = 0.8980044345898004\n",
            "Sensitivity = 0.8783068783068783\n",
            "Specitivity = 0.8980044345898004\n"
          ]
        }
      ],
      "source": [
        "logistic_l1 = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
        "logistic_l1_param_grid = {'C': np.array([0.01, 0.1, 1, 10, 100])}\n",
        "logistic_l1_cv = GridSearchCV(logistic_l1, logistic_l1_param_grid, cv=5,n_jobs=multiprocessing.cpu_count())\n",
        "logistic_l1_cv.fit(X_train,y_train)\n",
        "\n",
        "acc_train, prec_train, rec_train, f_train, sen_train, spec_train=metrics_for_evaluation(logistic_l1_cv, X_train, y_train)\n",
        "acc_test, prec_test, rec_test, f_test, sen_test, spec_test=metrics_for_evaluation(logistic_l1_cv, X_test, y_test)\n",
        "\n",
        "print(\"Logistic regression with L1 regularizer\")\n",
        "\n",
        "print(\"\\nFor train data:\")\n",
        "print(\"Accuracy =\", acc_train)\n",
        "print(\"Precision =\", prec_train)\n",
        "print(\"Recall =\", rec_train)\n",
        "print(\"F1 Score =\", f_train)\n",
        "print(\"Sensitivity =\", sen_train)\n",
        "print(\"Specitivity =\", spec_train)\n",
        "\n",
        "print(\"\\nFor test data:\")\n",
        "print(\"Accuracy =\", acc_test)\n",
        "print(\"Precision =\", prec_test)\n",
        "print(\"Recall =\", rec_test)\n",
        "print(\"F1 Score =\", f_test)\n",
        "print(\"Sensitivity =\", sen_test)\n",
        "print(\"Specitivity =\", spec_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM5GXWmJe1ix"
      },
      "outputs": [],
      "source": [
        "modelName = ['Logistic Regression (L2 Regularizer)','Logistic Regression (L1 Regularizer)','Soft-margin SVM (L2 Regularizer)','Soft-margin SVM (L1 Regularizer)',\n",
        "'Kernel SVM (RBF kernel)','KNN','Decision Tree','Random Forest']\n",
        "i = 0\n",
        "dataframe_best_params = pd.DataFrame({'Model Name':[],'Best parameters':[],'Best score':[]})\n",
        "for model in [logistic_l2_cv, logistic_l1_cv, svm_l2_cv, svm_l1_cv, svm_rbf_cv, knn_cv, dt_cv, rf_cv]:\n",
        "  dataframe_best_params.loc[len(dataframe_best_params.index)] = [modelName[i],model.best_params_,model.best_score_]\n",
        "  i +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foVE_PaOiPyt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "66df5267-0ca0-4173-e3c5-6c4a27545728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table for best parameters obtained after hyperparameter tuning in each model\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model Name                    Best parameters  \\\n",
              "0  Logistic Regression (L2 Regularizer)                         {'C': 0.1}   \n",
              "1  Logistic Regression (L1 Regularizer)                         {'C': 1.0}   \n",
              "2      Soft-margin SVM (L2 Regularizer)                         {'C': 0.1}   \n",
              "3      Soft-margin SVM (L1 Regularizer)                         {'C': 0.1}   \n",
              "4               Kernel SVM (RBF kernel)                    {'gamma': 0.01}   \n",
              "5                                   KNN                 {'n_neighbors': 1}   \n",
              "6                         Decision Tree  {'min_weight_fraction_leaf': 0.0}   \n",
              "7                         Random Forest              {'n_estimators': 250}   \n",
              "\n",
              "   Best score  \n",
              "0    0.884132  \n",
              "1    0.873874  \n",
              "2    0.880507  \n",
              "3    0.872364  \n",
              "4    0.882319  \n",
              "5    0.854860  \n",
              "6    0.806885  \n",
              "7    0.871458  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06e53f18-efd5-44de-b692-ff6ce03bcca0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Best parameters</th>\n",
              "      <th>Best score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression (L2 Regularizer)</td>\n",
              "      <td>{'C': 0.1}</td>\n",
              "      <td>0.884132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression (L1 Regularizer)</td>\n",
              "      <td>{'C': 1.0}</td>\n",
              "      <td>0.873874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Soft-margin SVM (L2 Regularizer)</td>\n",
              "      <td>{'C': 0.1}</td>\n",
              "      <td>0.880507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Soft-margin SVM (L1 Regularizer)</td>\n",
              "      <td>{'C': 0.1}</td>\n",
              "      <td>0.872364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kernel SVM (RBF kernel)</td>\n",
              "      <td>{'gamma': 0.01}</td>\n",
              "      <td>0.882319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>{'n_neighbors': 1}</td>\n",
              "      <td>0.854860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>{'min_weight_fraction_leaf': 0.0}</td>\n",
              "      <td>0.806885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>{'n_estimators': 250}</td>\n",
              "      <td>0.871458</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06e53f18-efd5-44de-b692-ff6ce03bcca0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06e53f18-efd5-44de-b692-ff6ce03bcca0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06e53f18-efd5-44de-b692-ff6ce03bcca0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "print(\"Table for best parameters obtained after hyperparameter tuning in each model\")\n",
        "dataframe_best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kea8Pl95IIW6"
      },
      "source": [
        "Observations: We can observe the best parameters for each model after hyperparameter tuning. Scores lie between 0 and 1. The higher the score, the better the model has performed while training with respect to that parameter.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG8y0M7gypp4"
      },
      "source": [
        "### Answer e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svV2sR5oXcaE"
      },
      "outputs": [],
      "source": [
        "dataframe_train = pd.DataFrame({'Model Name':[],'Accuracy':[],'Precision':[],'Recall':[],'F1 Score':[],'Specificity':[],'Senstivity':[]})\n",
        "dataframe_test = pd.DataFrame({'Model Name':[],'Accuracy':[],'Precision':[],'Recall':[],'F1 Score':[],'Specificity':[],'Senstivity':[]})\n",
        "modelName = ['Logistic Regression (L2 Regularizer)','Logistic Regression (L1 Regularizer)','Soft-margin SVM (L2 Regularizer)','Soft-margin SVM (L1 Regularizer)',\n",
        "'Kernel SVM (RBF kernel)','KNN','Decision Tree','Random Forest']\n",
        "i = 0\n",
        "for model in [logistic_l2_cv, logistic_l1_cv, svm_l2_cv, svm_l1_cv, svm_rbf_cv, knn_cv, dt_cv, rf_cv]:\n",
        "  accuracy_train, precision_train, recall_train, f1_train, sensitivity_train, specificity_train = metrics_for_evaluation(model, X_train, y_train)\n",
        "  accuracy_test, precision_test, recall_test, f1_test, sensitivity_test, specificity_test = metrics_for_evaluation(model, X_test, y_test)\n",
        "  dataframe_train.loc[len(dataframe_train.index)] = [modelName[i], accuracy_train, precision_train, recall_train, f1_train, sensitivity_train, specificity_train]\n",
        "  dataframe_test.loc[len(dataframe_test.index)] = [modelName[i], accuracy_test, precision_test, recall_test, f1_test, sensitivity_test, specificity_test]\n",
        "  i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laX2uxKHXcaF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "872344e9-be36-409f-ef9c-3e746769af35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabulated accuracy, precision, recall, specificity and senstivity values for training set\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model Name  Accuracy  Precision    Recall  \\\n",
              "0  Logistic Regression (L2 Regularizer)  0.933011   0.917890  0.959636   \n",
              "1  Logistic Regression (L1 Regularizer)  0.945081   0.934915  0.963616   \n",
              "2      Soft-margin SVM (L2 Regularizer)  0.941762   0.926007  0.967595   \n",
              "3      Soft-margin SVM (L1 Regularizer)  0.926976   0.926363  0.936896   \n",
              "4               Kernel SVM (RBF kernel)  0.937839   0.913692  0.974986   \n",
              "5                                   KNN  0.999095   0.998864  0.999431   \n",
              "6                         Decision Tree  0.999095   0.998864  0.999431   \n",
              "7                         Random Forest  0.999095   0.998864  0.999431   \n",
              "\n",
              "   F1 Score  Specificity  Senstivity  \n",
              "0  0.938299     0.902894    0.959636  \n",
              "1  0.949048     0.924116    0.963616  \n",
              "2  0.946344     0.912540    0.967595  \n",
              "3  0.931600     0.915756    0.936896  \n",
              "4  0.943344     0.895820    0.974986  \n",
              "5  0.999147     0.998714    0.999431  \n",
              "6  0.999147     0.998714    0.999431  \n",
              "7  0.999147     0.998714    0.999431  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b2d08a0-0375-4f16-ad03-06503fbd92ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Senstivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression (L2 Regularizer)</td>\n",
              "      <td>0.933011</td>\n",
              "      <td>0.917890</td>\n",
              "      <td>0.959636</td>\n",
              "      <td>0.938299</td>\n",
              "      <td>0.902894</td>\n",
              "      <td>0.959636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression (L1 Regularizer)</td>\n",
              "      <td>0.945081</td>\n",
              "      <td>0.934915</td>\n",
              "      <td>0.963616</td>\n",
              "      <td>0.949048</td>\n",
              "      <td>0.924116</td>\n",
              "      <td>0.963616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Soft-margin SVM (L2 Regularizer)</td>\n",
              "      <td>0.941762</td>\n",
              "      <td>0.926007</td>\n",
              "      <td>0.967595</td>\n",
              "      <td>0.946344</td>\n",
              "      <td>0.912540</td>\n",
              "      <td>0.967595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Soft-margin SVM (L1 Regularizer)</td>\n",
              "      <td>0.926976</td>\n",
              "      <td>0.926363</td>\n",
              "      <td>0.936896</td>\n",
              "      <td>0.931600</td>\n",
              "      <td>0.915756</td>\n",
              "      <td>0.936896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kernel SVM (RBF kernel)</td>\n",
              "      <td>0.937839</td>\n",
              "      <td>0.913692</td>\n",
              "      <td>0.974986</td>\n",
              "      <td>0.943344</td>\n",
              "      <td>0.895820</td>\n",
              "      <td>0.974986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.999095</td>\n",
              "      <td>0.998864</td>\n",
              "      <td>0.999431</td>\n",
              "      <td>0.999147</td>\n",
              "      <td>0.998714</td>\n",
              "      <td>0.999431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.999095</td>\n",
              "      <td>0.998864</td>\n",
              "      <td>0.999431</td>\n",
              "      <td>0.999147</td>\n",
              "      <td>0.998714</td>\n",
              "      <td>0.999431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.999095</td>\n",
              "      <td>0.998864</td>\n",
              "      <td>0.999431</td>\n",
              "      <td>0.999147</td>\n",
              "      <td>0.998714</td>\n",
              "      <td>0.999431</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b2d08a0-0375-4f16-ad03-06503fbd92ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b2d08a0-0375-4f16-ad03-06503fbd92ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b2d08a0-0375-4f16-ad03-06503fbd92ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "print(\"Tabulated accuracy, precision, recall, specificity and senstivity values for training set\")\n",
        "dataframe_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYrgk_UTXcaF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "c4b9dbbd-0b3c-4359-fbd9-43ca75b52326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabulated accuracy, precision, recall, specificity and senstivity values for test set\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Model Name  Accuracy  Precision    Recall  \\\n",
              "0  Logistic Regression (L2 Regularizer)  0.895054   0.888889  0.922395   \n",
              "1  Logistic Regression (L1 Regularizer)  0.889023   0.898004  0.898004   \n",
              "2      Soft-margin SVM (L2 Regularizer)  0.898673   0.899782  0.915743   \n",
              "3      Soft-margin SVM (L1 Regularizer)  0.887817   0.904977  0.886918   \n",
              "4               Kernel SVM (RBF kernel)  0.885404   0.851779  0.955654   \n",
              "5                                   KNN  0.882992   0.902273  0.880266   \n",
              "6                         Decision Tree  0.831122   0.859122  0.824834   \n",
              "7                         Random Forest  0.886610   0.860606  0.944568   \n",
              "\n",
              "   F1 Score  Specificity  Senstivity  \n",
              "0  0.905332     0.862434    0.922395  \n",
              "1  0.898004     0.878307    0.898004  \n",
              "2  0.907692     0.878307    0.915743  \n",
              "3  0.895857     0.888889    0.886918  \n",
              "4  0.900731     0.801587    0.955654  \n",
              "5  0.891134     0.886243    0.880266  \n",
              "6  0.841629     0.838624    0.824834  \n",
              "7  0.900634     0.817460    0.944568  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0baceb5-85aa-45c2-8fc6-37829dcbb313\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Senstivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression (L2 Regularizer)</td>\n",
              "      <td>0.895054</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.922395</td>\n",
              "      <td>0.905332</td>\n",
              "      <td>0.862434</td>\n",
              "      <td>0.922395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression (L1 Regularizer)</td>\n",
              "      <td>0.889023</td>\n",
              "      <td>0.898004</td>\n",
              "      <td>0.898004</td>\n",
              "      <td>0.898004</td>\n",
              "      <td>0.878307</td>\n",
              "      <td>0.898004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Soft-margin SVM (L2 Regularizer)</td>\n",
              "      <td>0.898673</td>\n",
              "      <td>0.899782</td>\n",
              "      <td>0.915743</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>0.878307</td>\n",
              "      <td>0.915743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Soft-margin SVM (L1 Regularizer)</td>\n",
              "      <td>0.887817</td>\n",
              "      <td>0.904977</td>\n",
              "      <td>0.886918</td>\n",
              "      <td>0.895857</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.886918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kernel SVM (RBF kernel)</td>\n",
              "      <td>0.885404</td>\n",
              "      <td>0.851779</td>\n",
              "      <td>0.955654</td>\n",
              "      <td>0.900731</td>\n",
              "      <td>0.801587</td>\n",
              "      <td>0.955654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.882992</td>\n",
              "      <td>0.902273</td>\n",
              "      <td>0.880266</td>\n",
              "      <td>0.891134</td>\n",
              "      <td>0.886243</td>\n",
              "      <td>0.880266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.831122</td>\n",
              "      <td>0.859122</td>\n",
              "      <td>0.824834</td>\n",
              "      <td>0.841629</td>\n",
              "      <td>0.838624</td>\n",
              "      <td>0.824834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.886610</td>\n",
              "      <td>0.860606</td>\n",
              "      <td>0.944568</td>\n",
              "      <td>0.900634</td>\n",
              "      <td>0.817460</td>\n",
              "      <td>0.944568</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0baceb5-85aa-45c2-8fc6-37829dcbb313')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0baceb5-85aa-45c2-8fc6-37829dcbb313 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0baceb5-85aa-45c2-8fc6-37829dcbb313');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "print(\"Tabulated accuracy, precision, recall, specificity and senstivity values for test set\")\n",
        "dataframe_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_8peCd2ym48"
      },
      "source": [
        "### Answer f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKlL2Rj3gKkO"
      },
      "source": [
        "Both L1 and L2 regularizers are used to avoid overfitting in linear models such as logistic regression and SVM. However, L1 regularization has a tendency to result in sparse models because it forces some of the coefficients to be exactly zero. On the other hand, L2 regularization does not force coefficients to be exactly zero but rather shrinks them towards zero.\n",
        "\n",
        "L1 regularization is often better suited for situations where there are many irrelevant features, as it allows for feature selection by setting some coefficients to zero. L2 regularization, on the other hand, is better suited for situations where all the features are relevant, as it avoids overfitting by shrinking all the coefficients towards zero.\n",
        "\n",
        "In practice, whether to use L1 or L2 regularization depends on the specific problem and data at hand. If the goal is to perform feature selection and obtain a sparse model, then L1 regularization should be used. If all the features are expected to be relevant, then L2 regularization should be used. In some cases, it may be useful to try both regularization techniques and compare their performance on the validation set.\n",
        "\n",
        "Overall, L1 regularization is a useful tool for feature selection in high-dimensional datasets where only a few features are expected to be relevant. However, it is important to note that L1 regularization may also result in a loss of information if important features are mistakenly set to zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h1of6YcjYsP"
      },
      "source": [
        "Performance of the models obtained using L1 and L2 regularizers can be compared from the table in part e. We also have to choose the evaluation metrics from accuracy, precision, recall, f1 score, sensitivity and specificity and decide which are important to us based on the problem statement related to the dataset. After deciding the metrics, we have to check which model gives higher values (close to 1) of those metrics.\n",
        "\n",
        "For example, if our chosen evaluation metric is accuracy then we can see that Logistic Regression and soft-margin SVM with L2 regularizer performs better than with L1 regularizer. If our chosen metric is precision then L2 regularizer gives better result than L1 regularizer. This is based on observations of test data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}